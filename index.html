<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Emotion Detection</title>

<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

<style>
body {
    margin: 0;
    width: 100vw;
    height: 100vh;
    overflow: hidden;
    font-family: Arial, sans-serif;

    display: flex;
    flex-direction: column;
    justify-content: center;
    align-items: center;

    background: #f0f0f0;
}

/* ===== Emoji Background ===== */
.emoji-bg {
    position: fixed;
    inset: 0;
    z-index: 0;
    pointer-events: none;
    overflow: hidden;
}

.emoji {
    position: absolute;
    font-size: 28px;
    opacity: 0.15;
    animation: float 18s linear infinite;
}

@keyframes float {
    from { transform: translateY(110vh) rotate(0deg); }
    to   { transform: translateY(-130vh) rotate(360deg); }
}

/* ===== UI ===== */
#status {
    margin-bottom: 12px;
    padding: 10px 16px;
    background: #333;
    color: #fff;
    border-radius: 6px;
    z-index: 2;
}

.container {
    z-index: 2;
    background: #fff;
    padding: 10px;
    border-radius: 10px;
    box-shadow: 0 8px 20px rgba(0,0,0,0.15);
}

canvas {
    display: block;
    border: 2px solid #333;
}
</style>

<script>
/* ===== Emoji Background ===== */
const emojis = ["üòÄ","üò°","üò±","üò¢","üòê","üòç","ü§¢","üòÆ"];

function createEmoji() {
    const e = document.createElement("div");
    e.className = "emoji";
    e.innerText = emojis[Math.floor(Math.random() * emojis.length)];
    e.style.left = Math.random() * 100 + "vw";
    e.style.fontSize = 24 + Math.random() * 24 + "px";
    e.style.animationDuration = 12 + Math.random() * 18 + "s";
    document.querySelector(".emoji-bg").appendChild(e);
    setTimeout(() => e.remove(), 35000);
}
setInterval(createEmoji, 500);

/* ===== Emotion Detection (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö) ===== */
let session;
let faceCascade;
const labels = ["Angry","Disgust","Fear","Happy","Sad","Surprise","Neutral"];

async function onOpenCvReady() {
    const status = document.getElementById("status");
    status.innerText = "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•...";
    session = await ort.InferenceSession.create("./emotion_yolo11n_cls.onnx");

    faceCascade = new cv.CascadeClassifier();
    const xml = "haarcascade_frontalface_default.xml";
    const res = await fetch(xml);
    cv.FS_createDataFile("/", xml, new Uint8Array(await res.arrayBuffer()), true, false);
    faceCascade.load(xml);

    status.innerText = "‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô";
    startVideo();
}

function startVideo() {
    const video = document.getElementById("videoInput");
    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
        video.srcObject = stream;
        video.onloadedmetadata = () => processVideo();
    });
}

async function processVideo() {
    const video = document.getElementById("videoInput");
    const canvas = document.getElementById("canvasOutput");
    const ctx = canvas.getContext("2d", { willReadFrequently: true });

    if (video.paused || video.ended) return;

    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    let src = cv.imread(canvas);
    let gray = new cv.Mat();
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    let faces = new cv.RectVector();
    faceCascade.detectMultiScale(gray, faces, 1.1, 3);

    for (let i = 0; i < faces.size(); i++) {
        let f = faces.get(i);

        /* ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö */
        ctx.strokeStyle = "#00ff00";
        ctx.lineWidth = 2;
        ctx.strokeRect(f.x, f.y, f.width, f.height);

        /* ==== ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö) ==== */
        const size = 64;
        const faceCanvas = document.createElement("canvas");
        faceCanvas.width = size;
        faceCanvas.height = size;
        const fCtx = faceCanvas.getContext("2d");

        fCtx.drawImage(canvas, f.x, f.y, f.width, f.height, 0, 0, size, size);
        const imgData = fCtx.getImageData(0, 0, size, size);

        const input = new Float32Array(1 * 3 * size * size);
        for (let c = 0; c < 3; c++) {
            for (let p = 0; p < size * size; p++) {
                input[c * size * size + p] =
                    imgData.data[p * 4 + c] / 255.0;
            }
        }

        const tensor = new ort.Tensor("float32", input, [1,3,size,size]);
        const output = await session.run({ [session.inputNames[0]]: tensor });
        const data = output[session.outputNames[0]].data;

        const idx = data.indexOf(Math.max(...data));
        const emotion = labels[idx] || "Unknown";

        /* ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå */
        ctx.fillStyle = "#00ff00";
        ctx.font = "18px Arial";
        ctx.fillText(emotion, f.x, f.y - 10);
    }

    src.delete();
    gray.delete();
    faces.delete();
    requestAnimationFrame(processVideo);
}
</script>

<script async src="https://docs.opencv.org/4.x/opencv.js" onload="onOpenCvReady()"></script>
</head>

<body>

<div class="emoji-bg"></div>

<div id="status">‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô...</div>

<div class="container">
    <video id="videoInput" width="640" height="480" autoplay playsinline style="display:none"></video>
    <canvas id="canvasOutput" width="640" height="480"></canvas>
</div>

</body>
</html>
